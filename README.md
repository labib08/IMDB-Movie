# Features
## Project Highlights
* Comprehensive comparison of **ZeroR, Decision Tree, Logistic Regression**, and **K-NN** models.
* Advanced data preprocessing, including **FastText** and **Doc2Vec** embeddings for non-numeric features.
* Extensive evaluation techniques such as **10-fold cross-validation** and **holdout strategies**.
* Hyperparameter tuning and feature engineering to maximize model performance and accuracy.
# Technologies Used
* **Python:** Core programming language.
* **Scikit-learn:** Model implementation and evaluation.
* **FastText:** Embedding generation for textual features.
* **Doc2Vec:** Vector representation for non-numeric data.
* **Logistic Regression, K-NN, Decision Trees:** Machine learning models for prediction.
# Methodologies
**1. Data Preprocessing:**

* Embedded non-numeric features using FastText and Doc2Vec.
* Performed feature selection to identify the most relevant attributes.
* Handled missing values and normalized numerical features.
**2. Model Comparison:**

* Implemented four supervised learning models:
** ZeroR: Baseline model.
** Decision Trees: Interpretable tree-based model with varying depths.
** Logistic Regression: Grid-searched hyperparameters for optimal performance.
** K-NN: Tuned distance metrics and K-values.
* Evaluated models using:
** **10-fold cross-validation.**
** **Holdout strategy for unseen data.**
* Conducted error analysis and statistical comparison of results.
**3. Critical Analysis:**

* Addressed overfitting in decision trees using various train-test splits.
* Investigated model performance metrics such as accuracy, precision, recall, and F1 score.
* Discussed strengths and weaknesses of each model.
